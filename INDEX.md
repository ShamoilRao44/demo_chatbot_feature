# ğŸ‰ Restaurant Management Chatbot - Complete Project

## ğŸ“¦ What You're Getting

A **production-grade, fully-functional** LLM-powered restaurant management chatbot backend that's **ready to run immediately**.

### âš¡ Quick Stats
- **1,405 lines** of production Python code
- **8 working functions** for restaurant management
- **Multi-turn conversations** with context awareness
- **Complete documentation** (3 guides: README, QUICKSTART, PROJECT_SUMMARY)
- **Test scripts** included
- **Docker ready**

---

## ğŸš€ Getting Started

### Choose Your Path:

#### ğŸƒ **Fast Track** (5 minutes)
ğŸ‘‰ Start here: **[QUICKSTART.md](./QUICKSTART.md)**
- Step-by-step setup
- Get running in 5 minutes
- Includes troubleshooting

#### ğŸ“š **Comprehensive Guide**
ğŸ‘‰ Read this: **[README.md](./README.md)**
- Full documentation
- Architecture details
- API reference
- Multiple examples

#### ğŸ“ **Understand the Project**
ğŸ‘‰ Review this: **[PROJECT_SUMMARY.md](./PROJECT_SUMMARY.md)**
- Implementation checklist
- Code metrics
- Extension points
- Learning outcomes

---

## ğŸ“‚ Project Structure

```
restaurant_agent/
â”œâ”€â”€ ğŸ“„ INDEX.md                    â† YOU ARE HERE
â”œâ”€â”€ ğŸ“„ QUICKSTART.md               â† Start here for quick setup
â”œâ”€â”€ ğŸ“„ README.md                   â† Full documentation
â”œâ”€â”€ ğŸ“„ PROJECT_SUMMARY.md          â† Technical overview
â”‚
â”œâ”€â”€ ğŸ app/                        â† Main application code
â”‚   â”œâ”€â”€ main.py                    â† FastAPI app & endpoints
â”‚   â”œâ”€â”€ config.py                  â† Configuration
â”‚   â”œâ”€â”€ db.py                      â† Database setup
â”‚   â”œâ”€â”€ models.py                  â† SQLAlchemy models
â”‚   â”œâ”€â”€ schemas.py                 â† Pydantic schemas
â”‚   â”œâ”€â”€ llm_client.py              â† Ollama LLM client
â”‚   â”œâ”€â”€ function_registry.py       â† Function system
â”‚   â”œâ”€â”€ utils.py                   â† Utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ actions/                   â† Function handlers
â”‚   â”‚   â”œâ”€â”€ dashboard.py           â† 4 dashboard functions
â”‚   â”‚   â””â”€â”€ menu.py                â† 4 menu functions
â”‚   â”‚
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ chat_session_service.py â† Chat orchestration
â”‚
â”œâ”€â”€ ğŸ› ï¸ seed_data.py                 â† Database seeding script
â”œâ”€â”€ ğŸ§ª test_requests.sh             â† Automated tests
â”œâ”€â”€ ğŸ“¦ requirements.txt             â† Python dependencies
â”œâ”€â”€ ğŸ³ Dockerfile                   â† Container definition
â”œâ”€â”€ ğŸ³ docker-compose.yml           â† Service orchestration
â”œâ”€â”€ âš™ï¸ .env.example                 â† Environment template
â””â”€â”€ ğŸ“ .gitignore                   â† Git ignore rules
```

---

## âœ… What's Implemented

### Core System
- [x] FastAPI backend with async support
- [x] PostgreSQL database with SQLAlchemy
- [x] Ollama LLM integration (LLaMA-3)
- [x] Multi-turn conversation engine
- [x] Session state management
- [x] Modular function registry

### 8 Demo Functions

**Dashboard:**
1. âœ“ Update business hours
2. âœ“ Update prep time  
3. âœ“ Pause/unpause restaurant
4. âœ“ Update address

**Menu:**
5. âœ“ Create menu groups
6. âœ“ Create menu items
7. âœ“ Update item prices
8. âœ“ Toggle item tags

### Documentation & Tools
- [x] 3 comprehensive guides
- [x] Database seeding script
- [x] Automated test script
- [x] Docker deployment
- [x] Example conversations

---

## ğŸ¯ Key Features

### 1ï¸âƒ£ Intelligent Conversations
```
User: "Change my hours"
Bot:  "Which day?" [collecting]
User: "Monday"  
Bot:  "What hours?" [collecting]
User: "9am-5pm"
Bot:  "Updated!" [executed]
```

### 2ï¸âƒ£ Structured Function Calling
LLM returns strict JSON:
- `ask_user` when info needed
- `call_function` when ready to execute

### 3ï¸âƒ£ Session Memory
- Maintains context across messages
- Stored in database
- Per-session state tracking

### 4ï¸âƒ£ Zero-Code Extensions
```python
# Add new function in 2 steps:
register_function("name", spec)  # 1. Register spec

@register_handler("name")        # 2. Add handler
async def handler(db, **args):
    return "Done!"
```

---

## ğŸƒ Quick Start Commands

```bash
# 1. Setup
cd restaurant_agent
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. Database
createdb restaurant_agent
python seed_data.py

# 3. Start Ollama (separate terminal)
ollama serve

# 4. Start API
uvicorn app.main:app --reload

# 5. Test
./test_requests.sh
```

**Or use Docker:**
```bash
docker-compose up
```

---

## ğŸ’¡ Example Usage

### Test the API
```bash
# Health check
curl http://localhost:8000/health

# List functions
curl http://localhost:8000/functions

# Chat
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "session_id": "test1",
    "owner_id": 1,
    "restaurant_id": 1,
    "message": "Set my prep time to 45 minutes"
  }'
```

### Multi-turn Example
See **[README.md](./README.md)** section "Example Conversations" for detailed walkthroughs.

---

## ğŸ”§ Technology Stack

- **Backend**: FastAPI (async)
- **Database**: PostgreSQL + SQLAlchemy
- **LLM**: Ollama (LLaMA-3)
- **Validation**: Pydantic
- **HTTP Client**: httpx (async)
- **Server**: Uvicorn

---

## ğŸ“Š Project Metrics

| Metric | Value |
|--------|-------|
| Total Python Lines | 1,405 |
| Functions Implemented | 8 |
| Database Models | 4 |
| API Endpoints | 4 |
| Documentation Pages | 3 |
| Test Scenarios | 8 |

---

## ğŸ“ Use This Project To Learn

1. **LLM Integration**: See how to structure prompts for function calling
2. **FastAPI Patterns**: Clean async API architecture
3. **Database Design**: Normalized schema with relationships
4. **Conversation AI**: Multi-turn dialogue management
5. **Code Organization**: Modular, extensible structure

---

## ğŸš€ Deployment Options

### Local Development
```bash
uvicorn app.main:app --reload
```

### Docker
```bash
docker-compose up
```

### Production
- Add Gunicorn for process management
- Use nginx as reverse proxy
- Set up PostgreSQL replication
- Add Redis for caching
- Implement monitoring (Prometheus/Grafana)

---

## ğŸ¤ Extend the System

### Add New Functions
1. Create function in `app/actions/`
2. Use `@register_function` decorator
3. Use `@register_handler` decorator
4. Import in `main.py`

**That's it!** No core logic changes needed.

### Add New Models
1. Define in `app/models.py`
2. Create migration (or use `init_db()`)
3. Add handlers in actions/

### Add Authentication
1. Add middleware in `main.py`
2. Update schemas with user context
3. Filter data by user in handlers

---

## ğŸ“ Support & Troubleshooting

### Common Issues

**"Database connection failed"**
- Check PostgreSQL is running
- Verify DATABASE_URL in .env

**"Ollama connection error"**  
- Ensure Ollama is running: `ollama serve`
- Verify model is pulled: `ollama pull llama3`

**"Function not working"**
- Check function is imported in `main.py`
- Verify function spec matches handler signature

See **[QUICKSTART.md](./QUICKSTART.md)** for detailed troubleshooting.

---

## âœ¨ What Makes This Special

1. **Complete Implementation**: Not a tutorial, a working system
2. **Production Patterns**: Real architecture, not simplified examples
3. **Extensible Design**: Add features without breaking existing code
4. **Comprehensive Docs**: 3 levels of documentation for different needs
5. **Ready to Deploy**: Docker, tests, seeding all included

---

## ğŸ¯ Next Steps

### Immediate:
1. Follow [QUICKSTART.md](./QUICKSTART.md) to get running
2. Test with [test_requests.sh](./test_requests.sh)
3. Read [README.md](./README.md) for details

### After Setup:
1. Explore the 8 demo functions
2. Try multi-turn conversations
3. Add your own function
4. Customize for your use case

### Advanced:
1. Add authentication
2. Implement caching
3. Add more LLM models
4. Build a frontend
5. Scale with load balancers

---

## ğŸ“„ File Guide

| File | Purpose | Lines |
|------|---------|-------|
| `main.py` | API endpoints & app setup | 113 |
| `llm_client.py` | Ollama integration | 197 |
| `function_registry.py` | Function system | 110 |
| `chat_session_service.py` | Chat orchestration | 165 |
| `dashboard.py` | 4 dashboard functions | 169 |
| `menu.py` | 4 menu functions | 220 |
| `models.py` | Database models | 79 |
| `utils.py` | Helper functions | 77 |

---

## ğŸ† Success Checklist

Before you start:
- [ ] Python 3.11+ installed
- [ ] PostgreSQL installed
- [ ] Ollama installed

After setup:
- [ ] Database created
- [ ] Dependencies installed
- [ ] Ollama running with llama3
- [ ] Test data seeded
- [ ] Server started
- [ ] Health check passes
- [ ] First chat request works

---

## ğŸ‰ You're Ready!

This is a **complete, working system**. Everything you need is here:

- âœ… Code that runs
- âœ… Database that works  
- âœ… Tests that pass
- âœ… Docs that guide
- âœ… Examples that teach

**Start with [QUICKSTART.md](./QUICKSTART.md) and you'll be chatting with your bot in 5 minutes!**

---

**Built with â¤ï¸ using FastAPI, PostgreSQL, and Ollama**

*Questions? Check the docs. Issues? See troubleshooting. Ready? Let's go!* ğŸš€